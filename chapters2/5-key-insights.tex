\section{Key Insights}%
\label{sec:Key Insights}
\subsection{Paper 1}%
\label{sub:Paper 1}






\subsection{Paper 2}%
\label{sub:Paper 2}
The author advocated the strongly consistent property of the etcd key-value store used by the current Kubernetes architecture has become the bottleneck in scaling the infrastructure horizontally and the use of an eventual consistent architecture instead.
Using the official etcd benchmarking tool, the author benchmarked the impact of increasing the cluster node count against the performance of the put (write) and the linearisable range (read) request from the etcd server.
As a result, the latency of the write request was severely impacted from 150ms grew to 280ms as the node counts increase from 5 to 21 due to the etcd must remain strongly consistent.
On the other hand, the latency of the read latency remained relatively low.
To overcome the bottleneck, the author suggested implementing an eventually consistent datastore instead via the conflict-free replicated datatypes (CRDTs).
Unfortunately, the author did highlight if conflict did happen, the Kubernetes controllers will have to decide and perform the conflict merging.
Nevertheless, a native horizontal autoscalar that optimizes the resources usage of the datastore may also be feasible via the transition towards an eventual consistent datastore.
In summary, a decentralized and eventual consistent store designed for Kubernetes will mitigate the bottleneck.












\subsection{Paper 3}%
\label{sub:Paper 3}
Based on the study, k3s had emerged as the most efficient light-weight Container Orchestration Distribution (COD) among other 3 alternatives.
Interestingly, despite k3s showed the lowest latency and highest throughput at 64 pods, Microshift and Microk8s had better performance when the deployment counts were lower than 16.
This insight may suggest the user to consider the scale of the deployment as part of their selection process, as mentioned by the author.
Further, the conclusion was made based on the assumption that the memory is the most paramount parameter in measuring the resource utilization score as the study focuses on light-weight IoT application where the memory resources are scarce.
The author also emphasized the flexibility of the developed evaluation model by tuning the weight of the different parameters.
The model combines resource utilization, control-plane deployment API and objects latency, allowing different study groups to emphasize certain property over another.

